//! –ü–∞—Ä—Å–µ—Ä —Å–∏–Ω—Ç–∞–∫—Å-–ø–æ–º–æ—â–Ω–∏–∫–∞ 1–° –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–∏–ø–∞—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
//! 
//! –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–∞—Ä—Å–µ—Ä–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
//! - –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ rayon
//! - Lock-free —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ DashMap
//! - –ü–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–∏–ø–∞—Ö, –º–µ—Ç–æ–¥–∞—Ö, —Å–≤–æ–π—Å—Ç–≤–∞—Ö
//! - –î–≤—É—è–∑—ã—á–Ω–æ—Å—Ç–∏ (—Ä—É—Å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
//! - –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞

use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::{Arc, atomic::{AtomicUsize, Ordering}};
use anyhow::{Result, Context};
use rayon::prelude::*;
use scraper::{Html, Selector};
use serde::{Deserialize, Serialize};
use tracing::{debug, info, warn};
use indicatif::{ProgressBar, ProgressStyle, MultiProgress};
use dashmap::DashMap;

use crate::core::types::FacetKind;

// ============================================================================
// –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
// ============================================================================

/// –£–∑–µ–ª –≤ –∏–µ—Ä–∞—Ä—Ö–∏–∏ —Å–∏–Ω—Ç–∞–∫—Å-–ø–æ–º–æ—â–Ω–∏–∫–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum SyntaxNode {
    /// –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–∏–ø–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä "–¢–∞–±–ª–∏—Ü–∞ –∑–Ω–∞—á–µ–Ω–∏–π")
    Category(CategoryInfo),
    /// –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä "–¢–∞–±–ª–∏—Ü–∞–ó–Ω–∞—á–µ–Ω–∏–π")
    Type(TypeInfo),
    /// –ú–µ—Ç–æ–¥ —Ç–∏–ø–∞
    Method(MethodInfo),
    /// –°–≤–æ–π—Å—Ç–≤–æ —Ç–∏–ø–∞  
    Property(PropertyInfo),
    /// –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä —Ç–∏–ø–∞
    Constructor(ConstructorInfo),
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–∏–ø–æ–≤
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CategoryInfo {
    pub name: String,
    pub catalog_path: String,
    pub description: String,
    pub related_links: Vec<String>,
    pub types: Vec<String>,
}

/// –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–µ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeInfo {
    pub identity: TypeIdentity,
    pub documentation: TypeDocumentation,
    pub structure: TypeStructure,
    pub metadata: TypeMetadata,
}

/// –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeIdentity {
    pub russian_name: String,
    pub english_name: String,
    pub catalog_path: String,
    pub aliases: Vec<String>,
    pub category_path: String,
}

/// –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Ç–∏–ø–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeDocumentation {
    pub category_description: Option<String>,
    pub type_description: String,
    pub examples: Vec<CodeExample>,
    pub availability: Vec<String>,
    pub since_version: String,
}

/// –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∏–ø–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeStructure {
    pub collection_element: Option<String>,
    pub methods: Vec<String>,
    pub properties: Vec<String>,
    pub constructors: Vec<String>,
    pub iterable: bool,
    pub indexable: bool,
}

/// –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ç–∏–ø–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TypeMetadata {
    pub available_facets: Vec<FacetKind>,
    pub default_facet: Option<FacetKind>,
    pub serializable: bool,
    pub exchangeable: bool,
    pub xdto_namespace: Option<String>,
    pub xdto_type: Option<String>,
}

/// –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CodeExample {
    pub description: Option<String>,
    pub code: String,
    pub language: String,
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç–æ–¥–µ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MethodInfo {
    pub name: String,
    pub english_name: Option<String>,
    pub description: Option<String>,
    pub parameters: Vec<ParameterInfo>,
    pub return_type: Option<String>,
    pub return_description: Option<String>,
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–≤–æ–π—Å—Ç–≤–µ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PropertyInfo {
    pub name: String,
    pub property_type: Option<String>,
    pub is_readonly: bool,
    pub description: Option<String>,
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–µ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConstructorInfo {
    pub name: String,
    pub parameters: Vec<ParameterInfo>,
    pub description: Option<String>,
}

/// –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ParameterInfo {
    pub name: String,
    pub type_name: Option<String>,
    pub is_optional: bool,
    pub default_value: Option<String>,
    pub description: Option<String>,
}

/// –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–∏–Ω—Ç–∞–∫—Å-–ø–æ–º–æ—â–Ω–∏–∫–∞
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct SyntaxHelperDatabase {
    pub nodes: HashMap<String, SyntaxNode>,
    pub methods: HashMap<String, MethodInfo>,
    pub properties: HashMap<String, PropertyInfo>,
    pub categories: HashMap<String, CategoryInfo>,
}

/// –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–∏–ø–æ–≤
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct TypeIndex {
    pub by_russian: HashMap<String, String>,
    pub by_english: HashMap<String, String>,
    pub by_any_name: HashMap<String, Vec<String>>,
    pub by_category: HashMap<String, Vec<String>>,
    pub by_facet: HashMap<FacetKind, Vec<String>>,
}

/// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
#[derive(Debug, Clone)]
pub struct OptimizationSettings {
    /// –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
    pub max_threads: Option<usize>,
    /// –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    pub batch_size: usize,
    /// –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    pub show_progress: bool,
    /// –õ–∏–º–∏—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    pub file_limit: Option<usize>,
    /// –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏
    pub skip_dirs: Vec<String>,
    /// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
    pub parallel_indexing: bool,
}

impl Default for OptimizationSettings {
    fn default() -> Self {
        Self {
            max_threads: None, // –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —è–¥—Ä–∞
            batch_size: 50,    // –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            show_progress: true,
            file_limit: None,
            skip_dirs: vec![
                "tables".to_string(),  // –ë–æ–ª—å—à–∏–µ —Ç–∞–±–ª–∏—Ü—ã –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                "IndexPackLookup".to_string(),
            ],
            parallel_indexing: true,
        }
    }
}

/// –ü–∞—Ä—Å–µ—Ä —Å–∏–Ω—Ç–∞–∫—Å-–ø–æ–º–æ—â–Ω–∏–∫–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç–∏
pub struct SyntaxHelperParser {
    /// –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å —É–∑–ª–∞–º–∏ (lock-free concurrent hashmap)
    pub(crate) nodes: Arc<DashMap<String, SyntaxNode>>,
    /// –ú–µ—Ç–æ–¥—ã (lock-free)
    methods: Arc<DashMap<String, MethodInfo>>,
    /// –°–≤–æ–π—Å—Ç–≤–∞ (lock-free)
    properties: Arc<DashMap<String, PropertyInfo>>,
    /// –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ (lock-free)
    categories: Arc<DashMap<String, CategoryInfo>>,
    
    /// –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ (—Å–æ–±–∏—Ä–∞—é—Ç—Å—è –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞)
    type_index: Arc<DashMap<String, TypeIndex>>,
    
    /// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    settings: OptimizationSettings,
    
    /// –°—á—ë—Ç—á–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    processed_files: Arc<AtomicUsize>,
    /// –°—á—ë—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞
    error_count: Arc<AtomicUsize>,
    /// –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
    total_files: Arc<AtomicUsize>,
}

impl SyntaxHelperParser {
    /// –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
    pub fn new() -> Self {
        Self::with_settings(OptimizationSettings::default())
    }
    
    /// –°–æ–∑–¥–∞—ë—Ç –ø–∞—Ä—Å–µ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    pub fn with_settings(settings: OptimizationSettings) -> Self {
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º rayon thread pool
        if let Some(threads) = settings.max_threads {
            rayon::ThreadPoolBuilder::new()
                .num_threads(threads)
                .build_global()
                .ok();
        }
        
        Self {
            nodes: Arc::new(DashMap::new()),
            methods: Arc::new(DashMap::new()),
            properties: Arc::new(DashMap::new()),
            categories: Arc::new(DashMap::new()),
            type_index: Arc::new(DashMap::new()),
            settings,
            processed_files: Arc::new(AtomicUsize::new(0)),
            error_count: Arc::new(AtomicUsize::new(0)),
            total_files: Arc::new(AtomicUsize::new(0)),
        }
    }
    
    /// –ü–∞—Ä—Å–∏—Ç –∫–∞—Ç–∞–ª–æ–≥ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
    pub fn parse_directory<P: AsRef<Path>>(&mut self, base_path: P) -> Result<()> {
        let base_path = base_path.as_ref();
        info!("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∏–∑ {:?}", base_path);
        
        // –§–∞–∑–∞ 1: –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ HTML —Ñ–∞–π–ª—ã
        let start = std::time::Instant::now();
        let html_files = self.collect_html_files(base_path)?;
        let file_count = html_files.len();
        self.total_files.store(file_count, Ordering::Relaxed);
        
        info!("üìä –ù–∞–π–¥–µ–Ω–æ {} HTML —Ñ–∞–π–ª–æ–≤ –∑–∞ {:?}", file_count, start.elapsed());
        
        // –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        let files_to_process = if let Some(limit) = self.settings.file_limit {
            &html_files[..limit.min(file_count)]
        } else {
            &html_files
        };
        
        info!("‚ö° –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {} —Ñ–∞–π–ª–æ–≤ —Å {} –ø–æ—Ç–æ–∫–∞–º–∏", 
            files_to_process.len(),
            rayon::current_num_threads()
        );
        
        // –°–æ–∑–¥–∞—ë–º –º—É–ª—å—Ç–∏-–ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        let multi_progress = if self.settings.show_progress {
            Some(MultiProgress::new())
        } else {
            None
        };
        
        // –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        let main_progress = if let Some(ref mp) = multi_progress {
            let pb = mp.add(ProgressBar::new(files_to_process.len() as u64));
            pb.set_style(
                ProgressStyle::default_bar()
                    .template("[{elapsed_precise}] {bar:40.cyan/blue} {pos}/{len} {msg} [{per_sec}]")?
                    .progress_chars("##-")
            );
            pb.set_message("–ü–∞—Ä—Å–∏–Ω–≥ HTML —Ñ–∞–π–ª–æ–≤");
            Some(pb)
        } else {
            None
        };
        
        // –§–∞–∑–∞ 2: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        let parse_start = std::time::Instant::now();
        
        files_to_process
            .par_chunks(self.settings.batch_size)
            .for_each(|batch| {
                self.process_batch(batch, &main_progress);
            });
        
        if let Some(pb) = main_progress {
            pb.finish_with_message(format!(
                "‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {:?}", 
                parse_start.elapsed()
            ));
        }
        
        // –§–∞–∑–∞ 3: –°–≤—è–∑—ã–≤–∞–µ–º —Ç–∏–ø—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
        info!("üîó –°–≤—è–∑—ã–≤–∞–µ–º —Ç–∏–ø—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏...");
        self.link_types_to_categories();
        
        // –§–∞–∑–∞ 4: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
        let index_start = std::time::Instant::now();
        
        if self.settings.parallel_indexing {
            self.build_indexes_parallel();
        } else {
            self.build_indexes();
        }
        
        info!("üìö –ò–Ω–¥–µ–∫—Å—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã –∑–∞ {:?}", index_start.elapsed());
        
        // –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        let processed = self.processed_files.load(Ordering::Relaxed);
        let errors = self.error_count.load(Ordering::Relaxed);
        let total_time = start.elapsed();
        
        info!("‚ú® –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {} —Ñ–∞–π–ª–æ–≤ –∑–∞ {:?}", processed, total_time);
        info!("üìà –°–∫–æ—Ä–æ—Å—Ç—å: {:.2} —Ñ–∞–π–ª–æ–≤/—Å–µ–∫", processed as f64 / total_time.as_secs_f64());
        
        if errors > 0 {
            warn!("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–æ {} –æ—à–∏–±–æ–∫ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ", errors);
        }
        
        Ok(())
    }
    
    /// –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ HTML —Ñ–∞–π–ª—ã —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    fn collect_html_files(&self, base_path: &Path) -> Result<Vec<PathBuf>> {
        use walkdir::WalkDir;
        
        let files: Vec<PathBuf> = WalkDir::new(base_path)
            .into_iter()
            .par_bridge()  // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –æ–±—Ö–æ–¥
            .filter_map(|entry| {
                entry.ok().and_then(|e| {
                    let path = e.path();
                    
                    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                    if path.is_dir() {
                        if let Some(dir_name) = path.file_name().and_then(|n| n.to_str()) {
                            if self.settings.skip_dirs.contains(&dir_name.to_string()) {
                                return None;
                            }
                        }
                    }
                    
                    // –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ HTML —Ñ–∞–π–ª—ã
                    if path.extension().and_then(|s| s.to_str()) == Some("html") {
                        Some(path.to_path_buf())
                    } else {
                        None
                    }
                })
            })
            .collect();
        
        Ok(files)
    }
    
    /// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á —Ñ–∞–π–ª–æ–≤
    fn process_batch(&self, batch: &[PathBuf], progress: &Option<ProgressBar>) {
        // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞
        batch.par_iter().for_each(|file_path| {
            match self.parse_html_file(file_path) {
                Ok(node) => {
                    self.save_node(node);
                    self.processed_files.fetch_add(1, Ordering::Relaxed);
                }
                Err(e) => {
                    debug!("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {:?}: {}", file_path, e);
                    self.error_count.fetch_add(1, Ordering::Relaxed);
                }
            }
            
            if let Some(pb) = progress {
                pb.inc(1);
            }
        });
    }
    
    /// –ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω HTML —Ñ–∞–π–ª
    fn parse_html_file(&self, path: &Path) -> Result<SyntaxNode> {
        let content = fs::read_to_string(path)
            .with_context(|| format!("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {:?}", path))?;
        let document = Html::parse_document(&content);
        
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –∏ –ø—É—Ç–∏
        let file_type = self.detect_file_type(path, &document);
        
        match file_type {
            FileType::Type => {
                let type_info = self.parse_type_from_document(path, &document)?;
                Ok(SyntaxNode::Type(type_info))
            }
            FileType::Method => {
                let method_info = self.parse_method_from_document(&document)?;
                Ok(SyntaxNode::Method(method_info))
            }
            FileType::Property => {
                let property_info = self.parse_property_from_document(&document)?;
                Ok(SyntaxNode::Property(property_info))
            }
            FileType::Category => {
                let category_info = self.parse_category_from_document(path, &document)?;
                Ok(SyntaxNode::Category(category_info))
            }
            FileType::Constructor => {
                let constructor_info = self.parse_constructor_from_document(&document)?;
                Ok(SyntaxNode::Constructor(constructor_info))
            }
        }
    }
    
    /// –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞
    fn detect_file_type(&self, path: &Path, document: &Html) -> FileType {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ñ–∞–π–ª–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ catalog*.html
        if let Some(file_name) = path.file_name().and_then(|n| n.to_str()) {
            if file_name.starts_with("catalog") && file_name.ends_with(".html") {
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ–¥–Ω–æ–∏–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
                if let Some(parent) = path.parent() {
                    let catalog_name = file_name.trim_end_matches(".html");
                    let catalog_dir = parent.join(catalog_name);
                    if catalog_dir.exists() && catalog_dir.is_dir() {
                        return FileType::Category;
                    }
                }
            }
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –ø—É—Ç–∏
        if let Some(parent) = path.parent() {
            if let Some(dir_name) = parent.file_name().and_then(|n| n.to_str()) {
                match dir_name {
                    "methods" => return FileType::Method,
                    "properties" => return FileType::Property,
                    "constructors" => return FileType::Constructor,
                    _ => {}
                }
            }
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        let title_selector = Selector::parse("h1.V8SH_pagetitle").unwrap_or_else(|_| {
            Selector::parse("h1").unwrap()
        });
        
        if let Some(title_elem) = document.select(&title_selector).next() {
            let title = title_elem.text().collect::<String>();
            
            // –ï—Å–ª–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –µ—Å—Ç—å —Å–∫–æ–±–∫–∏ - —ç—Ç–æ —Ç–∏–ø
            if title.contains('(') && title.contains(')') {
                return FileType::Type;
            }
            
            // –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç "." - —ç—Ç–æ –º–µ—Ç–æ–¥
            if title.contains('.') && !title.contains("...") {
                return FileType::Method;
            }
        }
        
        // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º —Ç–∏–ø–æ–º
        FileType::Type
    }
    
    /// –°–≤—è–∑—ã–≤–∞–µ—Ç —Ç–∏–ø—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—É—Ç–µ–π —Ñ–∞–π–ª–æ–≤
    fn link_types_to_categories(&self) {
        // –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        let categories_snapshot: Vec<(String, CategoryInfo)> = self.categories.iter()
            .map(|entry| (entry.key().clone(), entry.value().clone()))
            .collect();
        
        for (catalog_id, category) in categories_snapshot {
            debug!("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {}: {}", catalog_id, category.name);
            
            // –û–±–Ω–æ–≤–ª—è–µ–º —Ç–∏–ø—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            let pattern = format!("/{}/", catalog_id);
            
            // –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–∏–ø—ã –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for mut entry in self.nodes.iter_mut() {
                let path = entry.key();
                if path.contains(&pattern) {
                    if let SyntaxNode::Type(ref mut type_info) = entry.value_mut() {
                        type_info.identity.category_path = category.name.clone();
                        debug!("  –°–≤—è–∑–∞–ª —Ç–∏–ø {} —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π {}", 
                            type_info.identity.russian_name, category.name);
                    }
                }
            }
        }
    }
    
    /// –ü–∞—Ä—Å–∏—Ç —Ç–∏–ø –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    fn parse_type_from_document(&self, path: &Path, document: &Html) -> Result<TypeInfo> {
        let title = self.extract_title(document);
        let (russian, english) = self.parse_title(&title);
        let description = self.extract_description(document);
        
        Ok(TypeInfo {
            identity: TypeIdentity {
                russian_name: russian.clone(),
                english_name: english,
                catalog_path: self.build_path(path),
                category_path: self.extract_category_path(path),
                aliases: self.extract_aliases(document),
            },
            documentation: TypeDocumentation {
                category_description: None,
                type_description: description.clone(),
                examples: self.extract_examples(document),
                availability: self.extract_availability(document),
                since_version: self.extract_version(document),
            },
            structure: TypeStructure {
                collection_element: self.extract_collection_element(document),
                methods: Vec::new(), // –ë—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø–æ–∑–∂–µ
                properties: Vec::new(), // –ë—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø–æ–∑–∂–µ
                constructors: Vec::new(), // –ë—É–¥—É—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø–æ–∑–∂–µ
                iterable: self.is_iterable(&description),
                indexable: self.is_indexable(&description),
            },
            metadata: TypeMetadata {
                available_facets: self.detect_facets(&russian, &description),
                default_facet: None,
                serializable: self.is_serializable(document),
                exchangeable: self.is_exchangeable(document),
                xdto_namespace: None,
                xdto_type: None,
            },
        })
    }
    
    /// –ü–∞—Ä—Å–∏—Ç –º–µ—Ç–æ–¥ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    fn parse_method_from_document(&self, document: &Html) -> Result<MethodInfo> {
        let name = self.extract_title(document);
        let description = self.extract_description(document);
        let parameters = self.extract_parameters(document);
        let (return_type, return_description) = self.extract_return_info(document);
        
        Ok(MethodInfo {
            name: name.clone(),
            english_name: self.extract_english_name(document),
            description: Some(description),
            parameters,
            return_type,
            return_description,
        })
    }
    
    /// –ü–∞—Ä—Å–∏—Ç —Å–≤–æ–π—Å—Ç–≤–æ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    fn parse_property_from_document(&self, document: &Html) -> Result<PropertyInfo> {
        let name = self.extract_title(document);
        let description = self.extract_description(document);
        let property_type = self.extract_property_type(document);
        let is_readonly = self.is_readonly(document);
        
        Ok(PropertyInfo {
            name,
            property_type,
            is_readonly,
            description: Some(description),
        })
    }
    
    /// –ü–∞—Ä—Å–∏—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    fn parse_category_from_document(&self, path: &Path, document: &Html) -> Result<CategoryInfo> {
        let name = self.extract_title(document);
        let description = self.extract_description(document);
        let related_links = self.extract_links(document);
        let types = self.extract_type_list(document);
        
        // –ò–∑–≤–ª–µ–∫–∞–µ–º catalog ID –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        let catalog_id = path.file_stem()
            .and_then(|s| s.to_str())
            .unwrap_or("unknown")
            .to_string();
        
        Ok(CategoryInfo {
            name,
            catalog_path: catalog_id,
            description,
            related_links,
            types,
        })
    }
    
    /// –ü–∞—Ä—Å–∏—Ç –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    fn parse_constructor_from_document(&self, document: &Html) -> Result<ConstructorInfo> {
        let description = self.extract_description(document);
        let parameters = self.extract_parameters(document);
        
        Ok(ConstructorInfo {
            name: self.extract_title(document),
            description: Some(description),
            parameters,
        })
    }
    
    /// –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–∑–µ–ª –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (lock-free)
    fn save_node(&self, node: SyntaxNode) {
        match node {
            SyntaxNode::Category(cat) => {
                let path = cat.catalog_path.clone();
                self.categories.insert(path.clone(), cat.clone());
                self.nodes.insert(path, SyntaxNode::Category(cat));
            },
            SyntaxNode::Type(type_info) => {
                let path = type_info.identity.catalog_path.clone();
                self.nodes.insert(path, SyntaxNode::Type(type_info));
            },
            SyntaxNode::Method(method) => {
                let key = format!("method_{}", method.name);
                self.methods.insert(key.clone(), method.clone());
                self.nodes.insert(key, SyntaxNode::Method(method));
            },
            SyntaxNode::Property(prop) => {
                let key = format!("property_{}", prop.name);
                self.properties.insert(key.clone(), prop.clone());
                self.nodes.insert(key, SyntaxNode::Property(prop));
            },
            SyntaxNode::Constructor(cons) => {
                let key = format!("constructor_{}", self.nodes.len());
                self.nodes.insert(key, SyntaxNode::Constructor(cons));
            },
        }
    }
    
    /// –°—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–æ–¥–Ω–æ–ø–æ—Ç–æ—á–Ω–æ)
    fn build_indexes(&self) {
        let mut index = TypeIndex::default();
        
        for entry in self.nodes.iter() {
            let (path, node) = entry.pair();
            
            if let SyntaxNode::Type(type_info) = node {
                // –ò–Ω–¥–µ–∫—Å –ø–æ —Ä—É—Å—Å–∫–æ–º—É –∏–º–µ–Ω–∏
                index.by_russian.insert(
                    type_info.identity.russian_name.clone(),
                    path.clone()
                );
                
                // –ò–Ω–¥–µ–∫—Å –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É –∏–º–µ–Ω–∏
                if !type_info.identity.english_name.is_empty() {
                    index.by_english.insert(
                        type_info.identity.english_name.clone(),
                        path.clone()
                    );
                }
                
                // –ò–Ω–¥–µ–∫—Å –ø–æ —Ñ–∞—Å–µ—Ç–∞–º
                for facet in &type_info.metadata.available_facets {
                    index.by_facet
                        .entry(*facet)
                        .or_default()
                        .push(path.clone());
                }
                
                // –ò–Ω–¥–µ–∫—Å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                if !type_info.identity.category_path.is_empty() {
                    index.by_category
                        .entry(type_info.identity.category_path.clone())
                        .or_default()
                        .push(path.clone());
                }
            }
        }
        
        self.type_index.insert("main".to_string(), index);
    }
    
    /// –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
    fn build_indexes_parallel(&self) {
        use dashmap::DashMap;
        
        // –°–æ–∑–¥–∞—ë–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        let by_russian = Arc::new(DashMap::new());
        let by_english = Arc::new(DashMap::new());
        let by_facet = Arc::new(DashMap::new());
        let by_category = Arc::new(DashMap::new());
        
        // –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —É–∑–ª—ã
        self.nodes.iter().par_bridge().for_each(|entry| {
            let (path, node) = entry.pair();
            
            if let SyntaxNode::Type(type_info) = node {
                // –ò–Ω–¥–µ–∫—Å –ø–æ —Ä—É—Å—Å–∫–æ–º—É –∏–º–µ–Ω–∏
                by_russian.insert(
                    type_info.identity.russian_name.clone(),
                    path.clone()
                );
                
                // –ò–Ω–¥–µ–∫—Å –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É –∏–º–µ–Ω–∏
                if !type_info.identity.english_name.is_empty() {
                    by_english.insert(
                        type_info.identity.english_name.clone(),
                        path.clone()
                    );
                }
                
                // –ò–Ω–¥–µ–∫—Å –ø–æ —Ñ–∞—Å–µ—Ç–∞–º
                for facet in &type_info.metadata.available_facets {
                    by_facet
                        .entry(*facet)
                        .or_insert_with(Vec::new)
                        .push(path.clone());
                }
                
                // –ò–Ω–¥–µ–∫—Å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                if !type_info.identity.category_path.is_empty() {
                    by_category
                        .entry(type_info.identity.category_path.clone())
                        .or_insert_with(Vec::new)
                        .push(path.clone());
                }
            }
        });
        
        // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ–±—ã—á–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        let mut index = TypeIndex::default();
        
        for entry in by_russian.iter() {
            index.by_russian.insert(entry.key().clone(), entry.value().clone());
        }
        
        for entry in by_english.iter() {
            index.by_english.insert(entry.key().clone(), entry.value().clone());
        }
        
        for entry in by_facet.iter() {
            index.by_facet.insert(entry.key().clone(), entry.value().clone());
        }
        
        for entry in by_category.iter() {
            index.by_category.insert(entry.key().clone(), entry.value().clone());
        }
        
        self.type_index.insert("main".to_string(), index);
    }
    
    // =========================================================================
    // –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    // =========================================================================
    
    fn extract_title(&self, document: &Html) -> String {
        self.extract_element_text(document, "h1.V8SH_pagetitle")
            .or_else(|| self.extract_element_text(document, "h1"))
            .unwrap_or_default()
    }
    
    fn parse_title(&self, title: &str) -> (String, String) {
        if let Some(open) = title.find('(') {
            if let Some(close) = title.find(')') {
                let russian = title[..open].trim().to_string();
                let english = title[open+1..close].trim().to_string();
                return (russian, english);
            }
        }
        (title.trim().to_string(), String::new())
    }
    
    fn extract_element_text(&self, document: &Html, selector_str: &str) -> Option<String> {
        Selector::parse(selector_str).ok().and_then(|selector| {
            document.select(&selector)
                .next()
                .map(|e| e.text().collect::<String>().trim().to_string())
        })
    }
    
    fn extract_description(&self, document: &Html) -> String {
        if let Ok(selector) = Selector::parse("div.V8SH_descr p, p") {
            document.select(&selector)
                .map(|e| e.text().collect::<String>().trim().to_string())
                .filter(|s| !s.is_empty())
                .collect::<Vec<_>>()
                .join("\n")
        } else {
            String::new()
        }
    }
    
    fn extract_examples(&self, document: &Html) -> Vec<CodeExample> {
        let mut examples = Vec::new();
        
        if let Ok(selector) = Selector::parse("pre.V8SH_code, pre, code") {
            for elem in document.select(&selector) {
                let code = elem.text().collect::<String>().trim().to_string();
                if !code.is_empty() {
                    examples.push(CodeExample {
                        description: None,
                        code,
                        language: "bsl".to_string(),
                    });
                }
            }
        }
        
        examples
    }
    
    fn extract_parameters(&self, document: &Html) -> Vec<ParameterInfo> {
        let mut parameters = Vec::new();
        
        // –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if let Ok(selector) = Selector::parse("table.V8SH_params tr, table tr") {
            for row in document.select(&selector).skip(1) { // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                let cells: Vec<String> = Selector::parse("td").ok()
                    .map(|s| row.select(&s).map(|cell| {
                        cell.text().collect::<String>().trim().to_string()
                    }).collect())
                    .unwrap_or_default();
                
                if cells.len() >= 2 {
                    parameters.push(ParameterInfo {
                        name: cells[0].clone(),
                        type_name: Some(cells[1].clone()),
                        is_optional: cells.get(2)
                            .map(|s| s.contains("–ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π") || s.contains("Optional"))
                            .unwrap_or(false),
                        default_value: cells.get(3).cloned(),
                        description: cells.get(4).cloned(),
                    });
                }
            }
        }
        
        parameters
    }
    
    fn extract_return_info(&self, document: &Html) -> (Option<String>, Option<String>) {
        // –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏
        if let Ok(selector) = Selector::parse("div.V8SH_return, div.return") {
            if let Some(return_div) = document.select(&selector).next() {
                let text = return_div.text().collect::<String>();
                // –†–∞–∑–¥–µ–ª—è–µ–º —Ç–∏–ø –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
                if let Some(colon) = text.find(':') {
                    let return_type = text[..colon].trim().to_string();
                    let return_desc = text[colon+1..].trim().to_string();
                    return (Some(return_type), Some(return_desc));
                }
                return (Some(text.trim().to_string()), None);
            }
        }
        (None, None)
    }
    
    #[allow(dead_code)]
    fn extract_return_type(&self, document: &Html) -> String {
        self.extract_return_info(document).0.unwrap_or_default()
    }
    
    fn extract_property_type(&self, document: &Html) -> Option<String> {
        self.extract_element_text(document, "span.V8SH_type, span.type")
    }
    
    fn extract_english_name(&self, document: &Html) -> Option<String> {
        self.extract_element_text(document, "span.V8SH_english, span.english")
    }
    
    fn extract_availability(&self, document: &Html) -> Vec<String> {
        let mut availability = Vec::new();
        
        if let Ok(selector) = Selector::parse("div.V8SH_availability, div.availability") {
            if let Some(avail_div) = document.select(&selector).next() {
                let text = avail_div.text().collect::<String>();
                if text.contains("–°–µ—Ä–≤–µ—Ä") || text.contains("Server") {
                    availability.push("–°–µ—Ä–≤–µ—Ä".to_string());
                }
                if text.contains("–ö–ª–∏–µ–Ω—Ç") || text.contains("Client") {
                    availability.push("–ö–ª–∏–µ–Ω—Ç".to_string());
                }
                if text.contains("–ú–æ–±–∏–ª—å–Ω—ã–π") || text.contains("Mobile") {
                    availability.push("–ú–æ–±–∏–ª—å–Ω—ã–π".to_string());
                }
            }
        }
        
        if availability.is_empty() {
            availability = vec!["–°–µ—Ä–≤–µ—Ä".to_string(), "–ö–ª–∏–µ–Ω—Ç".to_string()];
        }
        
        availability
    }
    
    fn extract_version(&self, document: &Html) -> String {
        self.extract_element_text(document, "span.V8SH_version, span.version")
            .unwrap_or_else(|| "8.3.0+".to_string())
    }
    
    fn extract_aliases(&self, _document: &Html) -> Vec<String> {
        // –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∏–º–µ–Ω–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        Vec::new() // TODO: Implement alias extraction
    }
    
    fn extract_collection_element(&self, _document: &Html) -> Option<String> {
        // –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        None // TODO: Implement collection element extraction
    }
    
    fn extract_links(&self, document: &Html) -> Vec<String> {
        let mut links = Vec::new();
        
        if let Ok(selector) = Selector::parse("a.V8SH_link, a") {
            for link in document.select(&selector) {
                if let Some(href) = link.value().attr("href") {
                    links.push(href.to_string());
                }
            }
        }
        
        links
    }
    
    fn extract_type_list(&self, document: &Html) -> Vec<String> {
        let mut types = Vec::new();
        
        if let Ok(selector) = Selector::parse("ul.V8SH_types li, ul li") {
            for item in document.select(&selector) {
                let text = item.text().collect::<String>().trim().to_string();
                if !text.is_empty() {
                    types.push(text);
                }
            }
        }
        
        types
    }
    
    fn extract_category_path(&self, path: &Path) -> String {
        path.parent()
            .and_then(|p| p.to_str())
            .unwrap_or("")
            .to_string()
    }
    
    fn is_readonly(&self, document: &Html) -> bool {
        let text = document.root_element().text().collect::<String>();
        text.contains("–¢–æ–ª—å–∫–æ —á—Ç–µ–Ω–∏–µ") || text.contains("Read only")
    }
    
    fn is_iterable(&self, description: &str) -> bool {
        description.contains("–î–ª—è –∫–∞–∂–¥–æ–≥–æ") || 
        description.contains("For each") ||
        description.contains("–∏—Ç–µ—Ä–∞—Ü–∏—è") ||
        description.contains("iteration")
    }
    
    fn is_indexable(&self, description: &str) -> bool {
        description.contains("–∏–Ω–¥–µ–∫—Å") || 
        description.contains("index") ||
        description.contains("[]")
    }
    
    fn is_serializable(&self, document: &Html) -> bool {
        let text = document.root_element().text().collect::<String>();
        text.contains("–°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π") || 
        text.contains("Serializable") ||
        text.contains("XML") ||
        text.contains("JSON")
    }
    
    fn is_exchangeable(&self, document: &Html) -> bool {
        let text = document.root_element().text().collect::<String>();
        text.contains("–û–±–º–µ–Ω –¥–∞–Ω–Ω—ã–º–∏") || 
        text.contains("Data exchange") ||
        text.contains("XDTO")
    }
    
    fn detect_facets(&self, type_name: &str, description: &str) -> Vec<FacetKind> {
        let mut facets = vec![];
        
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞—Å–µ—Ç—ã –ø–æ –∏–º–µ–Ω–∏ —Ç–∏–ø–∞
        if type_name.ends_with("Manager") || type_name.contains("–ú–µ–Ω–µ–¥–∂–µ—Ä") {
            facets.push(FacetKind::Manager);
        }
        
        if type_name.ends_with("Object") || type_name.contains("–û–±—ä–µ–∫—Ç") {
            facets.push(FacetKind::Object);
        }
        
        if type_name.ends_with("Ref") || type_name.contains("–°—Å—ã–ª–∫–∞") {
            facets.push(FacetKind::Reference);
        }
        
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞—Å–µ—Ç—ã –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é
        if description.contains("–∫–æ–ª–ª–µ–∫—Ü–∏—è") || 
           description.contains("collection") ||
           description.contains("–î–ª—è –∫–∞–∂–¥–æ–≥–æ") ||
           type_name.contains("–¢–∞–±–ª–∏—Ü–∞") || 
           type_name.contains("Table") ||
           type_name.contains("–ú–∞—Å—Å–∏–≤") ||
           type_name.contains("Array") {
            facets.push(FacetKind::Collection);
        }
        
        if description.contains("—Å–æ–∑–¥–∞—Ç—å") || 
           description.contains("create") ||
           description.contains("–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä") {
            facets.push(FacetKind::Constructor);
        }
        
        facets
    }
    
    fn build_path(&self, path: &Path) -> String {
        // –°—Ç—Ä–æ–∏–º –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è —Å–∏–Ω—Ç–∞–∫—Å-–ø–æ–º–æ—â–Ω–∏–∫–∞
        path.components()
            .filter_map(|c| {
                if let std::path::Component::Normal(name) = c {
                    name.to_str()
                } else {
                    None
                }
            })
            .collect::<Vec<_>>()
            .join("/")
    }
    
    // =========================================================================
    // –ü—É–±–ª–∏—á–Ω—ã–π API
    // =========================================================================
    
    /// –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞—Ä—Å–∏–Ω–≥–∞
    pub fn get_stats(&self) -> ParsingStats {
        ParsingStats {
            total_files: self.total_files.load(Ordering::Relaxed),
            processed_files: self.processed_files.load(Ordering::Relaxed),
            error_count: self.error_count.load(Ordering::Relaxed),
            total_nodes: self.nodes.len(),
            types_count: self.nodes.iter()
                .filter(|entry| matches!(entry.value(), SyntaxNode::Type(_)))
                .count(),
            methods_count: self.methods.len(),
            properties_count: self.properties.len(),
            categories_count: self.categories.len(),
            index_size: self.type_index.get("main")
                .map(|idx| idx.by_russian.len() + idx.by_english.len())
                .unwrap_or(0),
        }
    }
    
    /// –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    pub fn export_database(&self) -> SyntaxHelperDatabase {
        let mut db = SyntaxHelperDatabase::default();
        
        // –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ —É–∑–ª—ã
        for entry in self.nodes.iter() {
            db.nodes.insert(entry.key().clone(), entry.value().clone());
        }
        
        // –ö–æ–ø–∏—Ä—É–µ–º –º–µ—Ç–æ–¥—ã
        for entry in self.methods.iter() {
            db.methods.insert(entry.key().clone(), entry.value().clone());
        }
        
        // –ö–æ–ø–∏—Ä—É–µ–º —Å–≤–æ–π—Å—Ç–≤–∞
        for entry in self.properties.iter() {
            db.properties.insert(entry.key().clone(), entry.value().clone());
        }
        
        // –ö–æ–ø–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        for entry in self.categories.iter() {
            db.categories.insert(entry.key().clone(), entry.value().clone());
        }
        
        db
    }
    
    /// –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã
    pub fn export_index(&self) -> TypeIndex {
        self.type_index
            .get("main")
            .map(|idx| idx.clone())
            .unwrap_or_default()
    }
    
    /// –ü–æ–∏—Å–∫ —Ç–∏–ø–∞ –ø–æ –∏–º–µ–Ω–∏
    pub fn find_type(&self, name: &str) -> Option<TypeInfo> {
        // –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –∏–Ω–¥–µ–∫—Å–µ
        if let Some(index) = self.type_index.get("main") {
            // –ò—â–µ–º –ø–æ —Ä—É—Å—Å–∫–æ–º—É –∏–º–µ–Ω–∏
            if let Some(path) = index.by_russian.get(name) {
                if let Some(node) = self.nodes.get(path) {
                    if let SyntaxNode::Type(type_info) = node.value() {
                        return Some(type_info.clone());
                    }
                }
            }
            
            // –ò—â–µ–º –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É –∏–º–µ–Ω–∏
            if let Some(path) = index.by_english.get(name) {
                if let Some(node) = self.nodes.get(path) {
                    if let SyntaxNode::Type(type_info) = node.value() {
                        return Some(type_info.clone());
                    }
                }
            }
        }
        
        None
    }
    
    /// –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ç–∏–ø—ã —Å –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º —Ñ–∞—Å–µ—Ç–æ–º
    pub fn get_types_by_facet(&self, facet: FacetKind) -> Vec<TypeInfo> {
        let mut types = Vec::new();
        
        if let Some(index) = self.type_index.get("main") {
            if let Some(paths) = index.by_facet.get(&facet) {
                for path in paths {
                    if let Some(node) = self.nodes.get(path) {
                        if let SyntaxNode::Type(type_info) = node.value() {
                            types.push(type_info.clone());
                        }
                    }
                }
            }
        }
        
        types
    }
}

/// –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ParsingStats {
    pub total_files: usize,
    pub processed_files: usize,
    pub error_count: usize,
    pub total_nodes: usize,
    pub types_count: usize,
    pub methods_count: usize,
    pub properties_count: usize,
    pub categories_count: usize,
    pub index_size: usize,
}

/// –¢–∏–ø —Ñ–∞–π–ª–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
enum FileType {
    Type,
    Method,
    Property,
    Category,
    Constructor,
}

impl Default for SyntaxHelperParser {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    use std::fs;
    
    #[test]
    fn test_parallel_parsing() {
        // –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ HTML —Ñ–∞–π–ª–∞–º–∏
        let temp_dir = TempDir::new().unwrap();
        let test_dir = temp_dir.path().join("test");
        fs::create_dir(&test_dir).unwrap();
        
        // –°–æ–∑–¥–∞—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö HTML —Ñ–∞–π–ª–æ–≤
        for i in 0..10 {
            let html = format!(r#"
                <html>
                <body>
                    <h1 class="V8SH_pagetitle">TestType{} (TestType{})</h1>
                    <p>Test description {}</p>
                </body>
                </html>
            "#, i, i, i);
            
            let file_path = test_dir.join(format!("type_{}.html", i));
            fs::write(file_path, html).unwrap();
        }
        
        // –ü–∞—Ä—Å–∏–º —Å –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å—é
        let settings = OptimizationSettings {
            max_threads: Some(4),
            batch_size: 2,
            show_progress: false,
            ..Default::default()
        };
        
        let mut parser = SyntaxHelperParser::with_settings(settings);
        parser.parse_directory(&test_dir).unwrap();
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        let stats = parser.get_stats();
        assert_eq!(stats.processed_files, 10);
        assert_eq!(stats.types_count, 10);
        assert_eq!(stats.error_count, 0);
    }
    
    #[test]
    fn test_concurrent_access() {
        use std::thread;
        use std::sync::Arc;
        
        let parser = Arc::new(SyntaxHelperParser::new());
        let mut handles = vec![];
        
        // –°–æ–∑–¥–∞—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        for i in 0..10 {
            let parser_clone = Arc::clone(&parser);
            let handle = thread::spawn(move || {
                // –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É–∑–ª–∞
                let type_info = TypeInfo {
                    identity: TypeIdentity {
                        russian_name: format!("–¢–∏–ø{}", i),
                        english_name: format!("Type{}", i),
                        catalog_path: format!("path_{}", i),
                        category_path: String::new(),
                        aliases: Vec::new(),
                    },
                    documentation: TypeDocumentation {
                        category_description: None,
                        type_description: format!("Description {}", i),
                        examples: Vec::new(),
                        availability: vec!["–°–µ—Ä–≤–µ—Ä".to_string()],
                        since_version: "8.3.0".to_string(),
                    },
                    structure: TypeStructure {
                        collection_element: None,
                        methods: Vec::new(),
                        properties: Vec::new(),
                        constructors: Vec::new(),
                        iterable: false,
                        indexable: false,
                    },
                    metadata: TypeMetadata {
                        available_facets: vec![],
                        default_facet: None,
                        serializable: true,
                        exchangeable: true,
                        xdto_namespace: None,
                        xdto_type: None,
                    },
                };
                
                parser_clone.save_node(SyntaxNode::Type(type_info));
            });
            
            handles.push(handle);
        }
        
        // –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
        for handle in handles {
            handle.join().unwrap();
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —É–∑–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
        assert_eq!(parser.nodes.len(), 10);
    }
}